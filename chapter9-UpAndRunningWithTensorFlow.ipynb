{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Hands On ML Chapter 9 - Up and Running with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## First Graph and First Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "InteractiveSession automatically sets itself as the default session. So you don't need \"with...\" but you need to close session manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A TensorFlow program is split into two parts: the first is called the construction phase, and second execution phase. First part builds computations, second runs it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Managing Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Any node you create is automatically added to the default graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sometimes you want to have multiple independent graphs. You can do it by creating new Graph and temporarily making it the default graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "x2.graph is graph, x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In Jupyter, when you experiment, you can have many duplicate nodes in default graph. Use tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Lifecycle of Node Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you dont want to evaluate w and x twice as it is done above, you should write code like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y,z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Linear Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.74651413e+01]\n",
      " [  4.35734153e-01]\n",
      " [  9.33829229e-03]\n",
      " [ -1.06622010e-01]\n",
      " [  6.44106984e-01]\n",
      " [ -4.25131839e-06]\n",
      " [ -3.77322501e-03]\n",
      " [ -4.26648885e-01]\n",
      " [ -4.40514028e-01]]\n"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    \n",
    "print (theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implementing Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Manually Computing the Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 11.0799\n",
      "Epoch 100 MSE = 0.839984\n",
      "Epoch 200 MSE = 0.629473\n",
      "Epoch 300 MSE = 0.597957\n",
      "Epoch 400 MSE = 0.577508\n",
      "Epoch 500 MSE = 0.562794\n",
      "Epoch 600 MSE = 0.552163\n",
      "Epoch 700 MSE = 0.54448\n",
      "Epoch 800 MSE = 0.538926\n",
      "Epoch 900 MSE = 0.534909\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Using autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 10.2892\n",
      "Epoch 100 MSE = 0.760861\n",
      "Epoch 200 MSE = 0.609923\n",
      "Epoch 300 MSE = 0.586806\n",
      "Epoch 400 MSE = 0.57165\n",
      "Epoch 500 MSE = 0.560396\n",
      "Epoch 600 MSE = 0.551959\n",
      "Epoch 700 MSE = 0.545604\n",
      "Epoch 800 MSE = 0.540796\n",
      "Epoch 900 MSE = 0.53714\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "gradients = tf.gradients(mse, [theta])[0] ## difference\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Using an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 11.782\n",
      "Epoch 100 MSE = 0.924677\n",
      "Epoch 200 MSE = 0.69712\n",
      "Epoch 300 MSE = 0.647044\n",
      "Epoch 400 MSE = 0.613353\n",
      "Epoch 500 MSE = 0.58904\n",
      "Epoch 600 MSE = 0.571424\n",
      "Epoch 700 MSE = 0.558647\n",
      "Epoch 800 MSE = 0.549373\n",
      "Epoch 900 MSE = 0.542634\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate) ##difference\n",
    "training_op = optimizer.minimize(mse) ## difference\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feeding Data tp the Training Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Placeholder is node used to pass the training data to TensorFlow during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 6.,  7.,  8.]], dtype=float32), array([[  9.,  10.,  11.],\n",
       "        [ 12.,  13.,  14.]], dtype=float32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1,2,3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4,5,6], [7,8,9]]})\n",
    "\n",
    "B_val_1, B_val_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855249]\n",
      " [ 0.8296333 ]\n",
      " [ 0.11875451]\n",
      " [-0.26555091]\n",
      " [ 0.3057158 ]\n",
      " [-0.00450219]\n",
      " [-0.03932687]\n",
      " [-0.89985287]\n",
      " [-0.87050968]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None,n + 1), name=\"X\")#difference\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")#difference\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate) \n",
    "training_op = optimizer.minimize(mse) \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):#difference\n",
    "    # load data from disk\n",
    "    \n",
    "    X_batch = scaled_housing_data_plus_bias\n",
    "    y_batch = housing.target.reshape(-1,1)\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):#difference\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    best_theta = theta.eval()\n",
    "    print (best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Saving and Restoring Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After training your model you should save its parameters to disk for future work. You can also save checkpoints during training so when your computer crashes during training you can start from the last checkpoint not from the begining.\n",
    "\n",
    "Saving is very easy with tensorflow. You need to add node Saver after all you Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.  6.  8.]]\n",
      "[[ 14.  16.  18.]]\n",
      "[[ 24.  26.  28.]]\n",
      "[[ 34.  36.  38.]]\n",
      "[[ 44.  46.  48.]]\n",
      "[[ 54.  56.  58.]]\n",
      "[[ 64.  66.  68.]]\n",
      "[[ 74.  76.  78.]]\n",
      "[[ 84.  86.  88.]]\n",
      "[[ 94.  96.  98.]]\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.Variable(2, name='x1', dtype='float32')\n",
    "x2 = tf.Variable([2,3,4], name='x2', dtype='float32')\n",
    "x3 = tf.Variable(1, name='x3', dtype='float32')\n",
    "x4 = tf.placeholder(tf.float32, shape=(None, 1), name=\"x4\")\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "f = x1 * x2 + x3 * x4\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(100):\n",
    "        if i % 10 == 0:\n",
    "            print(f.eval(feed_dict={x4: [[i]]}))\n",
    "            save_path = saver.save(sess, \"tmp/test_saver.ckpt\")\n",
    "    save_path = saver.save(sess, \"tmp/test_saver_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Restoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/test_saver.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"tmp/test_saver.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can decide which variables you want to save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver({\"weights\": theta}) #only theta variables with the name weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "By default the save() method also saves the structure of graph in file .meta. You can load this graph and add this to the default graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/test_saver.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.import_meta_graph(\"tmp/test_saver.ckpt.meta\")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"tmp/test_saver.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualising the Graph and Training Curves using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 11.5767\n",
      "Epoch 10 MSE = 0.524865\n",
      "Epoch 20 MSE = 0.524332\n",
      "Epoch 30 MSE = 0.524321\n",
      "Epoch 40 MSE = 0.524321\n",
      "Epoch 50 MSE = 0.524321\n",
      "Epoch 60 MSE = 0.524321\n",
      "Epoch 70 MSE = 0.524321\n",
      "Epoch 80 MSE = 0.524321\n",
      "Epoch 90 MSE = 0.524321\n",
      "[[ 2.06855249]\n",
      " [ 0.82963324]\n",
      " [ 0.11875443]\n",
      " [-0.26555082]\n",
      " [ 0.30571571]\n",
      " [-0.00450222]\n",
      " [-0.03932687]\n",
      " [-0.89985287]\n",
      " [-0.87050968]]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "n_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None,n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate) \n",
    "training_op = optimizer.minimize(mse) \n",
    "mse_summary = tf.summary.scalar('MSE', mse)#difference\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())#difference\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    # load data from disk\n",
    "    X_batch = scaled_housing_data_plus_bias\n",
    "    y_batch = housing.target.reshape(-1,1)\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:#difference\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    best_theta = theta.eval()\n",
    "    print (best_theta)\n",
    "    \n",
    "file_writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n",
      "loss/mse\n",
      "Epoch 0 MSE = 5.84354\n",
      "Epoch 10 MSE = 0.524344\n",
      "Epoch 20 MSE = 0.524321\n",
      "Epoch 30 MSE = 0.524321\n",
      "Epoch 40 MSE = 0.524321\n",
      "Epoch 50 MSE = 0.524321\n",
      "Epoch 60 MSE = 0.524321\n",
      "Epoch 70 MSE = 0.524321\n",
      "Epoch 80 MSE = 0.524321\n",
      "Epoch 90 MSE = 0.524321\n",
      "[[ 2.06855249]\n",
      " [ 0.82960552]\n",
      " [ 0.11874897]\n",
      " [-0.2655032 ]\n",
      " [ 0.30567697]\n",
      " [-0.00450376]\n",
      " [-0.03932568]\n",
      " [-0.89991796]\n",
      " [-0.87057185]]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "n_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None,n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "print(error.op.name)\n",
    "print(mse.op.name)\n",
    "    \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate) \n",
    "training_op = optimizer.minimize(mse) \n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    # load data from disk\n",
    "    X_batch = scaled_housing_data_plus_bias\n",
    "    y_batch = housing.target.reshape(-1,1)\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    best_theta = theta.eval()\n",
    "    print (best_theta)\n",
    "    \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
